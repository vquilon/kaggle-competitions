{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Rank Text Content by Semantic Similarity\n",
    "[Guide Reference](https://towardsdatascience.com/how-to-rank-text-content-by-semantic-similarity-4d2419a84c32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T20:27:44.891446Z",
     "iopub.status.busy": "2022-05-11T20:27:44.891446Z",
     "iopub.status.idle": "2022-05-11T20:27:47.929062Z",
     "shell.execute_reply": "2022-05-11T20:27:47.927115Z",
     "shell.execute_reply.started": "2022-05-11T20:27:44.891446Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "search_terms = 'fruit and vegetables'\n",
    "documents = ['cars drive on the road', 'tomatoes are actually fruit']\n",
    "\n",
    "doc_vectors = TfidfVectorizer().fit_transform([search_terms] + documents)\n",
    "\n",
    "cosine_similarities = linear_kernel(doc_vectors[0:1], doc_vectors).flatten()\n",
    "document_scores = [item.item() for item in cosine_similarities[1:]]\n",
    "# [0.0, 0.190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T20:27:51.888575Z",
     "iopub.status.busy": "2022-05-11T20:27:51.887571Z",
     "iopub.status.idle": "2022-05-11T20:28:01.041823Z",
     "shell.execute_reply": "2022-05-11T20:28:01.040822Z",
     "shell.execute_reply.started": "2022-05-11T20:27:51.888575Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to D:\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords list\n",
    "# nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "# Interface lemma tokenizer from nltk with sklearn\n",
    "class LemmaTokenizer:\n",
    "    ignore_tokens = [',', '.', ';', ':', '\"', '``', \"''\", '`']\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc) if t not in self.ignore_tokens]\n",
    "\n",
    "# Lemmatize the stop words\n",
    "tokenizer=LemmaTokenizer()\n",
    "token_stop = tokenizer(' '.join(stop_words))\n",
    "\n",
    "search_terms = 'red tomato'\n",
    "documents = ['cars drive on the road', 'tomatoes are actually fruit']\n",
    "\n",
    "# Create TF-idf model\n",
    "vectorizer = TfidfVectorizer(stop_words=token_stop, \n",
    "                              tokenizer=tokenizer)\n",
    "doc_vectors = vectorizer.fit_transform([search_terms] + documents)\n",
    "\n",
    "# Calculate similarity\n",
    "cosine_similarities = linear_kernel(doc_vectors[0:1], doc_vectors).flatten()\n",
    "document_scores = [item.item() for item in cosine_similarities[1:]]\n",
    "# [0.0, 0.287]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T20:28:16.058830Z",
     "iopub.status.busy": "2022-05-11T20:28:16.057829Z",
     "iopub.status.idle": "2022-05-11T20:28:23.827982Z",
     "shell.execute_reply": "2022-05-11T20:28:23.826982Z",
     "shell.execute_reply.started": "2022-05-11T20:28:16.058830Z"
    }
   },
   "outputs": [],
   "source": [
    "from re import sub\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "query_string = 'fruit and vegetables'\n",
    "documents = ['cars drive on the road', 'tomatoes are actually fruit']\n",
    "\n",
    "stopwords = ['the', 'and', 'are', 'a']\n",
    "\n",
    "# From: https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/soft_cosine_tutorial.ipynb\n",
    "def preprocess(doc):\n",
    "    # Tokenize, clean up input document string\n",
    "    doc = sub(r'<img[^<>]+(>|$)', \" image_token \", doc)\n",
    "    doc = sub(r'<[^<>]+(>|$)', \" \", doc)\n",
    "    doc = sub(r'\\[img_assist[^]]*?\\]', \" \", doc)\n",
    "    doc = sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', \" url_token \", doc)\n",
    "    return [token for token in simple_preprocess(doc, min_len=0, max_len=float(\"inf\")) if token not in stopwords]\n",
    "\n",
    "# Preprocess the documents, including the query string\n",
    "corpus = [preprocess(document) for document in documents]\n",
    "query = preprocess(query_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T20:28:29.323778Z",
     "iopub.status.busy": "2022-05-11T20:28:29.322781Z",
     "iopub.status.idle": "2022-05-11T20:29:09.679253Z",
     "shell.execute_reply": "2022-05-11T20:29:09.678247Z",
     "shell.execute_reply.started": "2022-05-11T20:28:29.323778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models import WordEmbeddingSimilarityIndex\n",
    "from gensim.similarities import SparseTermSimilarityMatrix\n",
    "from gensim.similarities import SoftCosineSimilarity\n",
    "\n",
    "# Load the model: this is a big file, can take a while to download and open\n",
    "glove = api.load(\"glove-wiki-gigaword-50\")    \n",
    "similarity_index = WordEmbeddingSimilarityIndex(glove)\n",
    "\n",
    "# Build the term dictionary, TF-idf model\n",
    "dictionary = Dictionary(corpus+[query])\n",
    "tfidf = TfidfModel(dictionary=dictionary)\n",
    "\n",
    "# Create the term similarity matrix.  \n",
    "similarity_matrix = SparseTermSimilarityMatrix(similarity_index, dictionary, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T20:29:31.465360Z",
     "iopub.status.busy": "2022-05-11T20:29:31.464360Z",
     "iopub.status.idle": "2022-05-11T20:29:31.485361Z",
     "shell.execute_reply": "2022-05-11T20:29:31.483363Z",
     "shell.execute_reply.started": "2022-05-11T20:29:31.464360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t 0.688 \t tomatoes are actually fruit\n",
      "0 \t 0.000 \t cars drive on the road\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\termsim.py:358: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  Y = np.multiply(Y, 1 / np.sqrt(Y_norm))\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\termsim.py:358: RuntimeWarning: invalid value encountered in multiply\n",
      "  Y = np.multiply(Y, 1 / np.sqrt(Y_norm))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Compute Soft Cosine Measure between the query and the documents.\n",
    "# From: https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/soft_cosine_tutorial.ipynb\n",
    "query_tf = tfidf[dictionary.doc2bow(query)]\n",
    "\n",
    "index = SoftCosineSimilarity(\n",
    "            tfidf[[dictionary.doc2bow(document) for document in corpus]],\n",
    "            similarity_matrix)\n",
    "\n",
    "doc_similarity_scores = index[query_tf]\n",
    "\n",
    "# Output the sorted similarity scores and documents\n",
    "sorted_indexes = np.argsort(doc_similarity_scores)[::-1]\n",
    "for idx in sorted_indexes:\n",
    "    print(f'{idx} \\t {doc_similarity_scores[idx]:0.3f} \\t {documents[idx]}')\n",
    "\n",
    "# 1    0.688    tomatoes are actually fruit\n",
    "# 0    0.000    cars drive on the road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
